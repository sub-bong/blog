---
title: "SIFT, CNN 소개 및 딥러닝 기반 객체 검출"
date: "2025-09-03"
keywords: ["TIL", "컴퓨터비전"]
---

# SIFT, CNN 소개 및 딥러닝 기반 객체 검출

## 1. 고급 특징점 기술과 매칭

- **SIFT (Scale-Invariant Feature Transform)**: 크기 및 회전 변화에 불변하는 지역 특징점을 검출하고 기술하는 알고리즘입니다. 해리스 특징점이 크기 변화에 취약한 단점을 극복했습니다.

  - **주요 단계**: 스케일 공간 구성(DoG) -> 특징점 검출 -> 방향 할당 -> 기술자(Descriptor) 생성.
  - **DoG (Difference of Gaussians)**: 가우시안 블러(blur)의 차이를 이용하여 스케일 변화에 강건한 특징점을 효율적으로 찾습니다.
  - **SIFT 기술자 (Descriptor)**: 특징점 주변의 그래디언트 방향 히스토그램을 사용하여 128차원의 벡터로 표현합니다. 이 벡터를 통해 특징점 간의 유사도를 비교할 수 있습니다.

- **특징점 매칭 (Feature Matching)**: 두 영상에서 추출된 특징점 기술자들을 비교하여 서로 짝을 맞추는 과정입니다.

  - **유사도 측정**: 기술자 벡터 간의 거리를 계산하여 유사도를 판단합니다. 유클리디안 거리(Euclidean Distance)가 일반적으로 사용됩니다.
  - **최근접 이웃 비율 테스트 (Nearest-Neighbor Ratio Test)**: 가장 가까운 이웃(NN1)과 두 번째로 가까운 이웃(NN2)의 거리 비율(NN1/NN2)을 계산하여, 이 비율이 특정 임계값보다 낮을 때만 신뢰할 수 있는 매칭으로 간주합니다. 모호한 매칭을 효과적으로 제거할 수 있습니다.

- **호모그래피 추정 (Homography Estimation)**: 두 영상 간의 기하학적 변환 관계(원근 변환)를 나타내는 행렬을 추정하는 것입니다. SIFT와 같은 특징점 매칭 결과를 이용하여 물체의 위치를 찾거나 영상을 정렬하는 데 사용됩니다.

## 2. 합성곱 신경망(CNN) 소개

- **전통적인 머신러닝 vs. 딥러닝**: 전통적인 방식에서는 특징 추출기(SIFT 등)를 사람이 직접 설계했지만, 딥러닝, 특히 CNN에서는 모델이 데이터로부터 최적의 필터(특징)를 스스로 학습합니다.

- **CNN (Convolutional Neural Network)**: 이미지 처리에 매우 강력한 성능을 보이는 딥러닝 모델입니다.

  - **핵심 아이디어**: 학습을 통해 최적의 컨볼루션 필터를 자동으로 찾아내어 이미지의 특징을 추출합니다.
  - **주요 특징**:
    1.  **지역적 연결 (Local Connectivity)**: 데이터의 공간적 구조를 유지하며, 인접한 픽셀 간의 관계를 효과적으로 학습합니다.
    2.  **가중치 공유 (Weight Sharing)**: 하나의 필터를 이미지 전체에 공유함으로써 학습할 파라미터 수를 크게 줄여 효율성을 높입니다.
    3.  **계층적 구조 (Hierarchical Structure)**: 여러 개의 층을 쌓아, 초기 층에서는 간단한 에지나 색상 같은 저수준 특징을, 깊은 층에서는 복잡한 형태나 객체의 일부 같은 고수준 특징을 학습합니다.

- **오버피팅 (Overfitting)**: 모델이 훈련 데이터에만 과도하게 최적화되어, 새로운 데이터에 대해서는 성능이 낮아지는 현상입니다. 일반화 능력이 부족한 상태를 의미합니다.

- **대표적인 컴퓨터 비전 데이터셋**: 파스칼 VOC (PASCAL VOC), 이미지넷 (ImageNet), 코코 (COCO) 등 대규모 데이터셋은 딥러닝 모델의 성능 발전에 결정적인 역할을 했습니다.

## 3. 딥러닝 기반 객체 검출 (Object Detection)

- **객체 검출**: 이미지 내에서 객체의 위치(바운딩 박스)와 클래스(종류)를 동시에 예측하는 문제입니다. 성능 척도로 **IoU (Intersection over Union)**가 사용됩니다.

- **2-Stage Detector (R-CNN 계열)**: "어디에 객체가 있을까?"를 먼저 제안하고, "그것이 무엇일까?"를 판별하는 2단계 접근 방식입니다.

  1.  **R-CNN**: 영역 제안(Selective Search) -> 각 제안 영역을 CNN에 독립적으로 입력 -> SVM으로 분류.
  2.  **Fast R-CNN**: 전체 이미지에 대해 한 번만 CNN을 통과시켜 특징 맵을 만들고, 이 특징 맵에서 영역 제안(RoI)에 해당하는 부분을 뽑아내어 처리 속도를 크게 향상시켰습니다.
  3.  **Faster R-CNN**: 영역 제안 과정까지 딥러닝 네트워크(RPN, Region Proposal Network)에 통합하여 거의 실시간에 가까운 성능을 달성했습니다.

- **1-Stage Detector (YOLO, SSD)**: 위치 탐색과 클래스 분류를 하나의 네트워크에서 동시에 처리하는 방식입니다.
  - **YOLO (You Only Look Once)**: 이미지를 그리드(grid)로 나누고, 각 그리드 셀이 바운딩 박스와 클래스 확률을 직접 예측합니다. 처리 속도가 매우 빠르지만, 작은 객체에 대한 정확도는 상대적으로 낮을 수 있습니다.

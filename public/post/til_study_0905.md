---
title: "생성 모델과 비전 트랜스포머"
date: "2025-09-05"
keywords: ["TIL", "컴퓨터비전"]
---

# 생성 모델과 비전 트랜스포머

## 1. 생성 모델 (Generative Models)

- **생성 모델 vs. 판별 모델**:

  - **판별 모델 (Discriminative Model)**: 데이터의 클래스를 구분하는 경계선을 학습합니다. (예: 개와 고양이를 구별)
  - **생성 모델 (Generative Model)**: 데이터의 실제 분포 자체를 학습하여, 존재할 법한 새로운 데이터를 생성해내는 모델입니다. (예: 세상에 없는 새로운 고양이 이미지 생성)

- **오토인코더 (Autoencoder)**: 자기 자신을 복원하도록 학습하는 비지도 학습 신경망입니다.

  - **구조**: 입력 데이터를 저차원의 잠재 공간(latent space)으로 압축하는 **인코더(Encoder)**와, 이 잠재 벡터로부터 원본 데이터를 복원하는 **디코더(Decoder)**로 구성됩니다.
  - **목적**: 차원 축소, 특징 학습, 데이터 압축 등에 사용됩니다. 데이터를 잘 압축하고 복원하는 과정에서 데이터의 핵심적인 특징을 학습하게 됩니다.

- **GAN (Generative Adversarial Network)**: 생성적 적대 신경망으로, 현재 가장 널리 사용되는 생성 모델 중 하나입니다.
  - **구조**:
    - **생성자 (Generator)**: 가짜 데이터를 만들어내는 역할을 합니다. (위조지폐범)
    - **판별자 (Discriminator)**: 생성자가 만든 데이터가 진짜인지 가짜인지 구별하는 역할을 합니다. (경찰)
  - **학습 방식**: 생성자는 판별자를 속이기 위해 점점 더 진짜 같은 데이터를 만들도록 학습하고, 판별자는 생성자의 데이터를 더 잘 구별해내도록 학습합니다. 이 둘이 서로 경쟁하며 함께 발전하는 적대적 학습(Adversarial Training)을 통해, 결국 생성자는 매우 사실적인 데이터를 만들 수 있게 됩니다.

## 2. 비전 트랜스포머 (Vision Transformer)

- **트랜스포머 (Transformer)**: 원래 자연어 처리(NLP) 분야에서 제안된 모델로, **어텐션(Attention)** 메커니즘을 기반으로 합니다. 문장 내 단어들의 관계를 파악하여 문맥을 이해하는 데 뛰어난 성능을 보였습니다.

- **어텐션 메커니즘 (Attention Mechanism)**: "전체 데이터 중에서 지금 중요한 부분에만 집중하자"는 아이디어입니다. CNN이 지역적인 정보(local feature)에 집중하는 반면, 어텐션은 이미지 전체의 픽셀 간 관계를 종합적으로 고려하여 전역적인 문맥(global context)을 파악할 수 있습니다.

- **ViT (Vision Transformer)**: 트랜스포머 모델을 컴퓨터 비전 분야에 적용한 것입니다.

  - **작동 방식**:
    1.  **패치 분할 (Patch Partition)**: 이미지를 바둑판처럼 여러 개의 작은 조각(패치, patch)으로 나눕니다.
    2.  **패치 임베딩 (Patch Embedding)**: 각 패치를 1차원 벡터로 만들고, 위치 정보를 추가하여 트랜스포머의 입력으로 사용합니다.
    3.  **트랜스포머 인코더**: 트랜스포머의 인코더를 통과시키면서 패치들 간의 관계를 학습합니다.
    4.  **분류**: 최종적으로 이미지 전체를 대표하는 특징 벡터를 이용하여 클래스를 분류합니다.

- **CNN vs. ViT**:
  - **데이터 효율성**: 데이터 양이 적거나 중간 크기일 때는 공간적 특징을 잘 학습하는 CNN이 더 우수한 성능을 보입니다.
  - **성능**: 이미지넷(ImageNet) 규모 이상의 대용량 데이터셋에서는 ViT가 CNN보다 더 높은 성능을 보이는 경향이 있습니다. 더 넓은 범위의 관계를 학습할 수 있기 때문입니다.
